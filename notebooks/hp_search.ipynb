{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import color.models as models\n",
    "import color.utils.utils as utils\n",
    "import color.hp_search as hp_search\n",
    "import color.training as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hp_config(hp_config, overwrite=False):\n",
    "    hp_dir = os.path.join('..', 'trained_models', 'hp', hp_config['hp_name'])\n",
    "    config_path = os.path.join(hp_dir, 'hp_config.pickle')\n",
    "    os.makedirs(hp_dir, exist_ok=overwrite)\n",
    "    with open(config_path, 'wb') as x:\n",
    "        pickle.dump(hp_config, x)\n",
    "    print('Saved to \"{}\"'.format(config_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP config template\n",
    "hp_config = {\n",
    "    'hp_name': None,\n",
    "    'model_key': None,\n",
    "    'model_params': [],\n",
    "    'training_params': {\n",
    "        'draw_plots': True,\n",
    "        'show_progress': True,\n",
    "        'use_cuda': True,\n",
    "    },\n",
    "    'dataset_params': {\n",
    "        'dataset': 'big',\n",
    "        'emb_len': 300,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Hyperparams\n",
    "hp_config_test = copy.deepcopy(hp_config)\n",
    "hp_config_test['hp_name'] = 'hp_test'\n",
    "hp_config_test['model_key'] = 'predict_color_rnn'\n",
    "hp_config_test['model_params'] = [{\n",
    "    'emb_dim': 50,\n",
    "    'hidden_dim': 10,\n",
    "    'num_layers': 1,\n",
    "    'dropout': 0,\n",
    "    'color_dim': 3,\n",
    "    'nonlinearity': 'relu',\n",
    "    'lr': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0\n",
    "}]*2\n",
    "if False:\n",
    "    save_hp_config(hp_config_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter generation for Sequence Models - Random Search\n",
    "\n",
    "num_models = 15\n",
    "model_params = []\n",
    "model_key = 'predict_color_rnn' # One of: predict_color_rnn, predict_name_rnn\n",
    "add_stop_word = False  # Only for model: predict_name_rnn\n",
    "\n",
    "count = 0\n",
    "while count < num_models:\n",
    "    \n",
    "    config = {\n",
    "        'emb_dim': hp_config['dataset_params']['emb_len'],\n",
    "        'name': 'rnn_{}'.format(\"{}\".format(count+1).zfill(3))\n",
    "    }\n",
    "    \n",
    "    # Model type\n",
    "    config['model_type'] = str(np.random.choice(['RNN', 'LSTM']))\n",
    "    config['nonlinearity'] = str(np.random.choice(['relu', 'tanh']))  # Only for model type RNN\n",
    "    \n",
    "    # Layer size and no of layers\n",
    "    config['hidden_dim'] = int(np.random.choice(list(map(lambda x: int((config['emb_dim'] * x) / 100), range(50, 200, 50)))))\n",
    "    config['num_layers'] = int(np.random.choice([1,2,3,4]))\n",
    "    \n",
    "    # Dropout; only for muilti-layer networks\n",
    "    if config['num_layers'] > 1:\n",
    "        config['dropout'] = -1\n",
    "        while config['dropout'] < 0 or config['dropout'] > 0.4:\n",
    "            config['dropout'] = float((0.2*np.random.randn()) + 0.2)\n",
    "    else:\n",
    "        config['dropout'] = 0\n",
    "    \n",
    "    # Learning rate (0.001 to 0.5)\n",
    "    config['lr'] = float(min(0.5, max(0.001, np.power(10, np.random.randn()-1.5))))\n",
    "    \n",
    "    # Momentum (0.85 to 0.92)\n",
    "    config['momentum'] = float(min(0.92, max(0.85, np.random.normal(0.9, 0.8))))\n",
    "    \n",
    "    # L2 regularization (1e-07 to 1e-04)\n",
    "    config['weight_decay'] = min(1e-04, float(np.power(10, 2*np.random.randn()-5)))\n",
    "    \n",
    "    # Learning rate decay; Every 1 to 3 epochs; Factor (0.9 to 1)\n",
    "    lr_step_size = int(np.random.choice(np.arange(1,3)))\n",
    "    lr_gamma = float(max(0.9, 1 - np.power(10, -2*np.random.rand())))\n",
    "    config['lr_decay'] = (lr_step_size, lr_gamma)\n",
    "    \n",
    "    # Loss function\n",
    "    if model_key == 'predict_name_rnn':\n",
    "        config['loss_fn'] = str(np.random.choice(['MSE', 'MSE_stop_word'])) if add_stop_word else 'MSE'\n",
    "        \n",
    "    # Validate hyperparameters and model size\n",
    "    model_class, _ = models.get_model(model_key)\n",
    "    model = model_class(**config)\n",
    "    num_params = utils.get_trainable_params(model)\n",
    "    print('Num params:', num_params)\n",
    "    if num_params < 500_000 or num_params > 3_000_000:\n",
    "        print('Num params out of range: {}. Skipping model:'.format(num_params))\n",
    "        print(config)\n",
    "        continue\n",
    "        \n",
    "    # Accept hyperparameters\n",
    "    model_params.append(config)\n",
    "    count += 1\n",
    "\n",
    "# Print generate hyperparameters\n",
    "for i, config in enumerate(model_params):\n",
    "    print('Model', i+1)\n",
    "    pprint.pprint(config)\n",
    "    \n",
    "# Save Hyperparams for sequence model\n",
    "hp_config_seq = copy.deepcopy(hp_config)\n",
    "\n",
    "hp_config_seq['hp_name'] = 'predict_color_seq_hp1'\n",
    "hp_config_seq['model_key'] = model_key\n",
    "\n",
    "hp_config_seq['training_params']['num_epochs'] = 6\n",
    "hp_config_seq['training_params']['seq_len_first'] = True\n",
    "\n",
    "hp_config_seq['dataset_params']['add_stop_word'] = add_stop_word\n",
    "\n",
    "hp_config_seq['model_params'] = model_params\n",
    "\n",
    "if True:\n",
    "    save_hp_config(hp_config_seq, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter generation for Sequence Models - Grid Search\n",
    "\n",
    "model_params = []\n",
    "model_key = 'predict_name_rnn' # One of: predict_color_rnn, predict_name_rnn\n",
    "add_stop_word = False  # Only for model: predict_name_rnn\n",
    "\n",
    "# Base hyperparameters\n",
    "config = {\n",
    "    'emb_dim': 300,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.91,\n",
    "    'hidden_dim': 300,\n",
    "    'num_layers': 3,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr_decay': (1, 0.9)\n",
    "}\n",
    "config_new = copy.deepcopy(config)\n",
    "config_new['name'] = 'seq_base'\n",
    "model_params.append(config_new)\n",
    "\n",
    "# Adjustments to base hyperparameters\n",
    "adj = [\n",
    "    ['momentum', 'momentum_low', 0.87],\n",
    "    ['momentum', 'momentum_high', 0.95],\n",
    "    ['weight_decay', 'l2_nil', 0],\n",
    "    ['weight_decay', 'l2_high', 1e-4],\n",
    "    ['lr_decay', 'lr_decay_high', (1, 0.7)],\n",
    "]\n",
    "for a_prop, a_name, a_val in adj:\n",
    "    config_new = copy.deepcopy(config)\n",
    "    config_new['name'] = 'seq_' + a_name\n",
    "    config_new[a_prop] = a_val\n",
    "    model_params.append(config_new)\n",
    "\n",
    "# Size adjustments\n",
    "adj = [\n",
    "    ['small', 100, 1],\n",
    "    ['large', 400, 4],\n",
    "]\n",
    "for a_name, a_hdim, a_nlayers in adj:\n",
    "    config_new = copy.deepcopy(config)\n",
    "    config_new['name'] = 'seq_' + a_name\n",
    "    config_new['hidden_dim'] = a_hdim\n",
    "    config_new['num_layers'] = a_nlayers\n",
    "    model_params.append(config_new)\n",
    "\n",
    "# Print generate hyperparameters\n",
    "for i, config in enumerate(model_params):\n",
    "    print('Model', i+1)\n",
    "    pprint.pprint(config)\n",
    "\n",
    "# Save Hyperparams for sequence model\n",
    "hp_config_seq = copy.deepcopy(hp_config)\n",
    "\n",
    "hp_config_seq['hp_name'] = 'predict_name_seq_hp1_grid'\n",
    "hp_config_seq['model_key'] = model_key\n",
    "\n",
    "hp_config_seq['training_params']['num_epochs'] = 10\n",
    "hp_config_seq['training_params']['seq_len_first'] = True\n",
    "\n",
    "hp_config_seq['dataset_params']['add_stop_word'] = add_stop_word\n",
    "\n",
    "hp_config_seq['model_params'] = model_params\n",
    "\n",
    "if True:\n",
    "    save_hp_config(hp_config_seq, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generte Hyperparams for CNN model (Color predictions)\n",
    "\n",
    "num_models = 15\n",
    "model_params = []\n",
    "model_key = 'predict_color_cnn'\n",
    "\n",
    "count = 0\n",
    "while count < num_models:\n",
    "    \n",
    "    config = {\n",
    "        'max_words': 3,\n",
    "        'name': 'cnn_{}'.format(\"{}\".format(count+1).zfill(3))\n",
    "    }\n",
    "    \n",
    "    # Conv + Pool blocks\n",
    "    config['num_conv_layers'] = int(np.random.choice([1,2,3,4]))\n",
    "    config['conv_kernel_size'] = int(np.random.choice([3,5,7,9]))\n",
    "    config['conv_stride'] = int(np.random.choice([1,2,3]))\n",
    "    \n",
    "    config['pool_kernel_size'] = int(np.random.choice([3,5,7,9]))\n",
    "    config['pool_stride'] = int(np.random.choice([1,2,3]))\n",
    "   \n",
    "    # Trailing linear layers\n",
    "    config['num_linear_layers'] = int(np.random.choice([0,1,2,3,4]))\n",
    "    config['linear_size_reduce'] = int(np.random.choice([1,2,3]))\n",
    "    \n",
    "    # Learning rate\n",
    "    config['lr'] = float(min(0.5, max(0.001, np.power(10, np.random.randn()-1.5))))\n",
    "    \n",
    "    # Momentum (0.8 to 0.97)\n",
    "    config['momentum'] = float(min(0.97, max(0.8, np.random.normal(0.9, 0.8))))\n",
    "    \n",
    "    # L2 regularization\n",
    "    config['weight_decay'] = min(1e-05, float(np.power(10, 2*np.random.randn()-5)))\n",
    "    \n",
    "    # Learning rate decay\n",
    "    lr_step_size = int(np.random.choice(np.arange(1,6)))\n",
    "    lr_gamma = float(max(0.9, 1 - np.power(10, -2*np.random.rand())))\n",
    "    config['lr_decay'] = (lr_step_size, lr_gamma)\n",
    "    \n",
    "    # Validate model strucure and no of parameters\n",
    "    try:\n",
    "        model_class, _ = models.get_model(model_key)\n",
    "        model = model_class(**config)\n",
    "    except AssertionError:\n",
    "        print('Invalid model')\n",
    "        print(config)\n",
    "        continue\n",
    "    num_params = utils.get_trainable_params(model)\n",
    "    print('Num params:', num_params)\n",
    "    if num_params < 500_000 or num_params > 3_000_000:\n",
    "        print('Num params out of range: {}. Skipping model:'.format(num_params))\n",
    "        print(config)\n",
    "        continue\n",
    "        \n",
    "    # Accept hyperparameters\n",
    "    model_params.append(config)\n",
    "    count += 1\n",
    "    \n",
    "# Print hyperparameters\n",
    "for i, config in enumerate(model_params):\n",
    "    print('Model', i+1)\n",
    "    pprint.pprint(config)\n",
    "    \n",
    "# Save Hyperparams for LSTM model (Color predictions)\n",
    "hp_config_cnn = copy.deepcopy(hp_config)\n",
    "hp_config_cnn['hp_name'] = 'predict_color_cnn_r2'\n",
    "hp_config_cnn['model_key'] = 'predict_color_cnn'\n",
    "hp_config_cnn['training_params']['num_epochs'] = 5\n",
    "hp_config_cnn['model_params'] = model_params\n",
    "if False:\n",
    "    save_hp_config(hp_config_cnn, overwrite=False)\n",
    "\n",
    "# Save Hyperparams for sequence model\n",
    "hp_config_cnn = copy.deepcopy(hp_config)\n",
    "\n",
    "hp_config_cnn['hp_name'] = 'predict_color_cnn_hp1'\n",
    "hp_config_cnn['model_key'] = model_key\n",
    "\n",
    "hp_config_cnn['training_params']['num_epochs'] = 6\n",
    "\n",
    "hp_config_cnn['dataset_params']['max_words'] = 3\n",
    "hp_config_cnn['dataset_params']['pad_len'] = 3\n",
    "\n",
    "hp_config_cnn['model_params'] = model_params\n",
    "\n",
    "if True:\n",
    "    save_hp_config(hp_config_cnn, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lr</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nonlinearity</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>momentum</th>\n",
       "      <th>train_loss_min</th>\n",
       "      <th>cv_loss_min</th>\n",
       "      <th>lr_decay</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rnn_008</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>7.303276e-08</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.151657</td>\n",
       "      <td>0.157444</td>\n",
       "      <td>(2, 0.9)</td>\n",
       "      <td>good, mild overfit but converging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnn_002</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083029</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.161343</td>\n",
       "      <td>(2, 0.9)</td>\n",
       "      <td>overfit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnn_001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "      <td>0.253945</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.157965</td>\n",
       "      <td>0.161954</td>\n",
       "      <td>(2, 0.9797120820765007)</td>\n",
       "      <td>good, about to saturate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rnn_006</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.159224</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>(2, 0.9)</td>\n",
       "      <td>good, slow to converge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rnn_010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>225</td>\n",
       "      <td>3</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.884157e-09</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.159601</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>(2, 0.9)</td>\n",
       "      <td>good, slow to converge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnn_004</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.218275</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>(1, 0.9)</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rnn_007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.142181</td>\n",
       "      <td>0.164758</td>\n",
       "      <td>(1, 0.9)</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnn_003</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>225</td>\n",
       "      <td>4</td>\n",
       "      <td>0.295649</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.800701</td>\n",
       "      <td>0.161160</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>(1, 0.9462830749466179)</td>\n",
       "      <td>ok, slow to converge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnn_005</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.230913</td>\n",
       "      <td>0.236760</td>\n",
       "      <td>(2, 0.9653344048428644)</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rnn_009</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.123173</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.344502</td>\n",
       "      <td>0.300437</td>\n",
       "      <td>(2, 0.9828709929420816)</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name        lr  hidden_dim  num_layers   dropout nonlinearity  \\\n",
       "7  rnn_008  0.002494         225           1  0.000000         relu   \n",
       "1  rnn_002  0.009010         225           2  0.083029         tanh   \n",
       "0  rnn_001  0.001000         600           4  0.253945         relu   \n",
       "5  rnn_006  0.001000         450           1  0.000000         tanh   \n",
       "9  rnn_010  0.001000         225           3  0.096579         tanh   \n",
       "3  rnn_004  0.021637         600           2  0.218275         tanh   \n",
       "6  rnn_007  0.100000         300           1  0.000000         relu   \n",
       "2  rnn_003  0.001000         225           4  0.295649         tanh   \n",
       "4  rnn_005  0.100000         225           1  0.000000         relu   \n",
       "8  rnn_009  0.100000         600           2  0.123173         relu   \n",
       "\n",
       "   weight_decay  momentum  train_loss_min  cv_loss_min  \\\n",
       "7  7.303276e-08  0.910000        0.151657     0.157444   \n",
       "1  1.000000e-06  0.800000        0.147300     0.161343   \n",
       "0  1.000000e-06  0.910000        0.157965     0.161954   \n",
       "5  1.000000e-06  0.800000        0.159224     0.162421   \n",
       "9  1.884157e-09  0.800000        0.159601     0.162528   \n",
       "3  1.000000e-06  0.910000        0.147986     0.164173   \n",
       "6  1.000000e-06  0.800000        0.142181     0.164758   \n",
       "2  1.000000e-06  0.800701        0.161160     0.165361   \n",
       "4  1.000000e-06  0.910000        0.230913     0.236760   \n",
       "8  1.000000e-06  0.910000        0.344502     0.300437   \n",
       "\n",
       "                  lr_decay                            remarks  \n",
       "7                 (2, 0.9)  good, mild overfit but converging  \n",
       "1                 (2, 0.9)                            overfit  \n",
       "0  (2, 0.9797120820765007)            good, about to saturate  \n",
       "5                 (2, 0.9)             good, slow to converge  \n",
       "9                 (2, 0.9)             good, slow to converge  \n",
       "3                 (1, 0.9)                               poor  \n",
       "6                 (1, 0.9)                               poor  \n",
       "2  (1, 0.9462830749466179)               ok, slow to converge  \n",
       "4  (2, 0.9653344048428644)                               poor  \n",
       "8  (2, 0.9828709929420816)                               poor  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models\n",
    "\n",
    "hp_name = 'predict_name_seq_hp1'\n",
    "hp_dir = os.path.join(hp_search.hp_dir_base, hp_name)\n",
    "config_path = os.path.join(hp_dir, 'hp_config.pickle')\n",
    "hp_config = hp_search.load_model_configs(config_path)\n",
    "\n",
    "# Load training parameters for all models\n",
    "model_info = []\n",
    "for model_params in hp_config['model_params']:\n",
    "    save_dir = os.path.join(hp_search.hp_dir_base, hp_name, model_params['name'])\n",
    "    if os.path.isdir(save_dir):\n",
    "        model_info.append(training.load_training_params(save_dir))\n",
    "    else:\n",
    "        model_info.append(None)\n",
    "\n",
    "# Create model comparison dataframe\n",
    "model_params_df = pd.DataFrame(hp_config['model_params'])\n",
    "model_params_df['epochs_trained'] = list(map(lambda m: None if m is None else len(m['epoch_train_losses']), model_info))\n",
    "model_params_df['train_loss_min'] = list(map(lambda m: None if m is None or len(m['epoch_train_losses']) <= 0 else m['epoch_train_losses'][-1], model_info))\n",
    "model_params_df['cv_loss_min'] = list(map(lambda m: None if m is None or len(m['epoch_cv_losses']) <= 0  else m['epoch_cv_losses'][-1], model_info))\n",
    "model_params_df['training_time'] = list(map(lambda m: None if m is None else sum(m['epoch_durations']), model_info))\n",
    "model_params_df = model_params_df.fillna('')\n",
    "\n",
    "# Some remarks for model selection\n",
    "model_params_df['remarks'] = [\n",
    "    'good, about to saturate',#1\n",
    "    'overfit',\n",
    "    'ok, slow to converge',\n",
    "    'poor',#4\n",
    "    'poor',\n",
    "    'good, slow to converge',\n",
    "    'poor',#7\n",
    "    'good, mild overfit but converging',\n",
    "    'poor',\n",
    "    'good, slow to converge',#10\n",
    "]\n",
    "\n",
    "if False:\n",
    "    save_path = os.path.join(hp_dir, 'model_comparison.csv')\n",
    "    model_params_df.to_csv(save_path)\n",
    "\n",
    "model_params_df[['name', 'lr', 'hidden_dim', 'num_layers', 'dropout', 'nonlinearity', 'weight_decay', \n",
    "                 'momentum', 'train_loss_min', 'cv_loss_min', 'lr_decay', 'remarks']].sort_values('cv_loss_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>lr</th>\n",
       "      <th>lr_decay</th>\n",
       "      <th>momentum</th>\n",
       "      <th>name</th>\n",
       "      <th>nonlinearity</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>epochs_trained</th>\n",
       "      <th>train_loss_min</th>\n",
       "      <th>cv_loss_min</th>\n",
       "      <th>training_time</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.096579</td>\n",
       "      <td>300</td>\n",
       "      <td>225</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(2, 0.9)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>rnn_010</td>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>1.884157e-09</td>\n",
       "      <td>15</td>\n",
       "      <td>0.159601</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>637.360285</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dropout  emb_dim  hidden_dim     lr  lr_decay  momentum     name  \\\n",
       "9  0.096579      300         225  0.001  (2, 0.9)       0.8  rnn_010   \n",
       "\n",
       "  nonlinearity  num_layers  weight_decay  epochs_trained  train_loss_min  \\\n",
       "9         tanh           3  1.884157e-09              15        0.159601   \n",
       "\n",
       "   cv_loss_min  training_time remarks  \n",
       "9     0.162528     637.360285          "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize train/cv errors for any model\n",
    "\n",
    "def plot_losses(model_info):\n",
    "    num_epochs = len(model_info['epoch_train_losses'])\n",
    "    epochs = np.arange(num_epochs) + 1\n",
    "    plt.plot(epochs, model_info['epoch_train_losses'], label='Training Loss')\n",
    "    plt.plot(epochs, model_info['epoch_cv_losses'], label='CV Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.show()\n",
    "\n",
    "model_info_dict = {m['name']: model_info[i] for i, m in enumerate(hp_config['model_params'])}\n",
    "m = 'rnn_010'\n",
    "plot_losses(model_info_dict[m])\n",
    "model_params_df[model_params_df['name'] == m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lr</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout</th>\n",
       "      <th>nonlinearity</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>momentum</th>\n",
       "      <th>train_loss_min</th>\n",
       "      <th>cv_loss_min</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnn_001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>600</td>\n",
       "      <td>0.253945</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.157965</td>\n",
       "      <td>0.161954</td>\n",
       "      <td>good, about to saturate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rnn_006</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.159224</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>good, slow to converge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rnn_008</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>7.303276e-08</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.151657</td>\n",
       "      <td>0.157444</td>\n",
       "      <td>good, mild overfit but converging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rnn_010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>225</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.884157e-09</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.159601</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>good, slow to converge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name        lr  hidden_dim   dropout nonlinearity  weight_decay  \\\n",
       "0  rnn_001  0.001000         600  0.253945         relu  1.000000e-06   \n",
       "5  rnn_006  0.001000         450  0.000000         tanh  1.000000e-06   \n",
       "7  rnn_008  0.002494         225  0.000000         relu  7.303276e-08   \n",
       "9  rnn_010  0.001000         225  0.096579         tanh  1.884157e-09   \n",
       "\n",
       "   momentum  train_loss_min  cv_loss_min                            remarks  \n",
       "0      0.91        0.157965     0.161954            good, about to saturate  \n",
       "5      0.80        0.159224     0.162421             good, slow to converge  \n",
       "7      0.91        0.151657     0.157444  good, mild overfit but converging  \n",
       "9      0.80        0.159601     0.162528             good, slow to converge  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out some well performing models\n",
    "filtered = model_params_df[['name', 'lr', 'hidden_dim', 'dropout', 'nonlinearity', 'weight_decay', \n",
    "                 'momentum', 'train_loss_min', 'cv_loss_min', 'remarks']]\n",
    "filtered[filtered['remarks'].str.contains('good')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colornamer",
   "language": "python",
   "name": "colornamer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
